# -*- coding: utf-8 -*-
"""CreditCard_PythonCode using only GLRM(NB3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qpl-eWwLOxz56_WYdo8IefR8ifNAYQ8f
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import glob
import os
import scipy.stats as ss
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from __future__ import print_function
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.metrics.cluster import homogeneity_score
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OrdinalEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
import matplotlib.cm as cm
# %matplotlib inline

# Read data 
os.chdir('/content/drive/My Drive/Colab Notebooks/credit_card_project')
datapath = os.getcwd()+'/data/'
file = datapath + 'creditcardpro.csv'
df = pd.read_csv(file, sep = ',', index_col = 0)

# Rename column 'PAY_0' as 'PAY_1'
df.rename(columns = {'PAY_0' : 'PAY_1'}, inplace = True)

# Print dataframe and column datatypes
pd.options.display.max_columns = None
#print(df.head(5))
#print(df.dtypes)

# Create lists of continuous and categorical column names
continuous_cols = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',
                   'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
                   'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']
categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_1', 'PAY_2', 'PAY_3',
                    'PAY_4', 'PAY_5', 'PAY_6', 'default.payment.next.month']

# Assign 'object' datatype to categorical columns                    
df[categorical_cols] = df[categorical_cols].astype('category')

# Print unique values for categorical columns
unique_values = {col:list(df[col].unique()) for col in categorical_cols}
for key, value in unique_values.items():
  print(key,value)

# Adjust categorical column values for misrepresented entries
df.loc[~df['EDUCATION'].isin([1, 2, 3, 4]), 'EDUCATION'] = 5
df.loc[~df['MARRIAGE'].isin([1, 2]), 'MARRIAGE'] = 3
df.loc[~df['PAY_1'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_1'] = 0
df.loc[~df['PAY_2'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_2'] = 0
df.loc[~df['PAY_3'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_3'] = 0
df.loc[~df['PAY_4'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_4'] = 0
df.loc[~df['PAY_5'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_5'] = 0
df.loc[~df['PAY_6'].isin([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'PAY_6'] = 0
categorical_cols = categorical_cols[:-1]

df.head()

# len(df.loc["EDUCATION"]==5)
# df[df.iloc[:,2]==5]
edu=len(df[df.iloc[:,2]==5])
mar=len(df[df.iloc[:,3]==3])
pay1=len(df[df.iloc[:,5]==0])
pay2=len(df[df.iloc[:,6]==0])
pay3=len(df[df.iloc[:,7]==0])
pay4=len(df[df.iloc[:,8]==0])
pay5=len(df[df.iloc[:,9]==0])
pay6=len(df[df.iloc[:,10]==0])
x=np.array(["Education","marriage","Pay_1","Pay_2","Pay_3","Pay_4","Pay_5","Pay_6"])
y=np.array([edu,mar,pay1,pay2,pay3,pay4,pay5,pay6])
y
#type(y)

import matplotlib.pyplot as plt
plt.bar(x,y,color="purple")
plt.xticks(rotation=60)

plt.xlabel("Features")
plt.ylabel("New Category")
plt.title("Features that belong to new category")
plt.legend()
plt.savefig("bargraph.jpg")
plt.show()

# Install Java
! apt-get install default-jre
! java -version
# Install h2o library for GLRM
! pip install h2o

import h2o # For GLRM
from h2o.estimators.glrm import H2OGeneralizedLowRankEstimator
h2o.init()
h2o.remove_all() # Clean slate - just in case the cluster was already running

# Write updated dataframe into a single CSV file
df.to_csv('data/partial_training.csv', columns = df.columns)

# Import data as h2o dataframe
dfh2o = h2o.import_file(path = os.path.realpath("data/partial_training.csv"))
dfh2o.types

# Reset categorical column data types in h2o dataframe
dfh2o[categorical_cols] = dfh2o[categorical_cols].asfactor()
dfh2o["default.payment.next.month"] = dfh2o["default.payment.next.month"].asfactor()
dfh2o.types

# Basic GLRM using absolute loss for continuous and categorical loss for
# categorical colimns with no regularization and with stadardized columns
model = H2OGeneralizedLowRankEstimator(k = 10,
                                       loss = "Absolute", multi_loss = "Categorical",
                                       transform = "Standardize",
                                       regularization_x = "None",
                                       regularization_y = "None",
                                       max_iterations = 1000,
                                       min_step_size = 1e-6)
model.train(training_frame = dfh2o)
model.show()

# Print importance of each component of GLRM model
model._model_json["output"]["importance"]

# Split the feature matrix into product of two matrices X and Y
# The matrix X has the same number of rows as the original feature matrix
# but a reduced number of columns representing the original features
# GLRM matrix factors X and Y
X_matrix = h2o.get_frame(model._model_json["output"]["representation_name"])
print(X_matrix)
Y_matrix = model._model_json["output"]["archetypes"]
print(Y_matrix)

# Data for training and testing
X = np.array(h2o.as_list(X_matrix))
print(X.shape)
y = df['default.payment.next.month'].to_numpy()
print(y.shape)

# Stratified train & test split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.25)

from sklearn.linear_model import LogisticRegression 
classifier_LR = LogisticRegression(random_state = 42) 
classifier_LR.fit(X_train,y_train)

y_pred_LR= classifier_LR.predict(X_test)

from sklearn.metrics import confusion_matrix 
cm_LR= confusion_matrix(y_test, y_pred_LR) 
print ("Confusion Matrix : \n", cm_LR)

from sklearn.metrics import accuracy_score 
print ("Accuracy : ", accuracy_score(y_test, y_pred_LR)) 

specificity1 = cm_LR[0,0]/(cm_LR[0,0]+cm_LR[0,1])
print('specificity : ', specificity1 )

sensitivity1 = cm_LR[1,1]/(cm_LR[1,0]+cm_LR[1,1])
print('Sensitivity : ', sensitivity1)

from sklearn.metrics import classification_report
matrix = classification_report(y_test,y_pred_LR,labels=[1,0])
print('Classification report : \n',matrix)

from sklearn.svm import SVC
classifier_SVM_linear=SVC(kernel='linear',random_state=42)
classifier_SVM_linear.fit(X_train,y_train)

y_pred_SVM_linear= classifier_SVM_linear.predict(X_test)

from sklearn.metrics import confusion_matrix 
cm_SVM_linear = confusion_matrix(y_test, y_pred_SVM_linear) 
print ("Confusion Matrix : \n", cm_SVM_linear)

from sklearn.metrics import accuracy_score 
print ("Accuracy : ", accuracy_score(y_test, y_pred_SVM_linear)) 
specificity = cm_SVM_linear[0,0]/(cm_SVM_linear[0,0]+cm_SVM_linear[0,1])
print('Speci : ', specificity )

sensitivity = cm_SVM_linear[1,1]/(cm_SVM_linear[1,0]+cm_SVM_linear[1,1])
print('Sensi : ', sensitivity)

from sklearn.metrics import classification_report
matrix = classification_report(y_test,y_pred_LR,labels=[1,0])
print('Classification report : \n',matrix)

from sklearn import tree
classifier_DT = tree.DecisionTreeClassifier()
classifier_DT.fit(X_train,y_train)

y_pred_DT= classifier_DT.predict(X_test)

from sklearn.metrics import confusion_matrix 
cm_DT = confusion_matrix(y_test, y_pred_DT) 
print ("Confusion Matrix : \n", cm_DT)

from sklearn.metrics import accuracy_score 
print ("Accuracy : ", accuracy_score(y_test, y_pred_DT))
speci = cm_DT[0,0]/(cm_DT[0,0]+cm_DT[0,1])
print('Speci : ', speci )

sensi = cm_DT[1,1]/(cm_DT[1,0]+cm_DT[1,1])
print('Sensi : ', sensi)

from sklearn.metrics import classification_report
matrix_DT = classification_report(y_test,y_pred_DT,labels=[1,0])
print('Classification report : \n',matrix_DT)

from sklearn.svm import SVC
classifier_SVM_rbf=SVC(kernel='rbf',random_state=0)
classifier_SVM_rbf.fit(X_train,y_train)

y_pred_SVM_rbf= classifier_SVM_rbf.predict(X_test)

from sklearn.metrics import confusion_matrix 
cm_svm_rbf = confusion_matrix(y_test, y_pred_SVM_rbf) 
print ("Confusion Matrix : \n", cm_svm_rbf)

from sklearn.metrics import accuracy_score 
print ("Accuracy : ", accuracy_score(y_test, y_pred_SVM_rbf))
speci1 = cm_svm_rbf[0,0]/(cm_svm_rbf[0,0]+cm_svm_rbf[0,1])
print('Speci : ', speci1 )

sensi = cm_svm_rbf[1,1]/(cm_svm_rbf[1,0]+cm_svm_rbf[1,1])
print('Sensi : ', sensi)

from sklearn.metrics import classification_report
matrix_svm_rbf = classification_report(y_test,y_pred_SVM_rbf,labels=[1,0])
print('Classification report : \n',matrix_svm_rbf)

from sklearn.svm import SVC
classifier_SVM_poly=SVC(kernel='poly',random_state=0)
classifier_SVM_poly.fit(X_train,y_train)

y_pred_SVM_poly= classifier_SVM_poly.predict(X_test)

from sklearn.metrics import confusion_matrix 
cm_svm_poly = confusion_matrix(y_test, y_pred_SVM_poly) 
print ("Confusion Matrix : \n", cm_svm_poly)

from sklearn.metrics import accuracy_score 
print ("Accuracy : ", accuracy_score(y_test, y_pred_SVM_poly))
speci = cm_svm_poly[0,0]/(cm_svm_poly[0,0]+cm_svm_poly[0,1])
print('Specifi : ', speci )

sensi = cm_svm_poly[1,1]/(cm_svm_poly[1,0]+cm_svm_poly[1,1])
print('Sensi : ', sensi)

from sklearn.metrics import classification_report
matrix_svm_ploy = classification_report(y_test,y_pred_SVM_poly,labels=[1,0])
print('Classification report : \n',matrix_svm_ploy)

y_pred_prob_LR = classifier_LR.predict_proba(X_test)[:,1]
#y_pred_prob_SVM_Li = classifier_SVM_linear.predict_proba(X_test)[:,1]
y_pred_prob_DT = classifier_DT.predict_proba(X_test)[:,1]
y_pred_prob_SVM_rbf = classifier_SVM_rbf.predict_proba(X_test)[:,1]
y_pred_prob_SVM_poly = classifier_SVM_poly.predict_proba(X_test)[:,1]
from sklearn.metrics import average_precision_score, auc, roc_curve, precision_recall_curve
average_precision1 = average_precision_score(y_test, y_pred_prob_LR)
#average_precision2 = average_precision_score(y_test, y_pred_prob_SVM_Li)
average_precision3 = average_precision_score(y_test, y_pred_prob_DT)
average_precision4 = average_precision_score(y_test, y_pred_prob_SVM_rbf)
average_precision5 = average_precision_score(y_test, y_pred_prob_SVM_poly)

#print('Average precision-recall score RF: {}'.format(average_precision))

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precision1, recall1, _ = precision_recall_curve(y_test, y_pred_prob_LR)
precision2, recall2, _ = precision_recall_curve(y_test, y_pred_prob_SVM_Li)
precision3, recall3, _ = precision_recall_curve(y_test, y_pred_prob_DT)
precision4, recall4, _ = precision_recall_curve(y_test, y_pred_prob_SVM_rbf)
precision5, recall5, _ = precision_recall_curve(y_test, y_pred_prob_SVM_poly)


plt.step(np.array([recall1,recall2.recall3,recall4,recall5]), np.array([precision1,precision2,precision3,precision4,precision5]), color='b', 
         alpha=0.2, where='post')
#plt.fill_between(recall, precision, step='post', alpha=0.2,
                 #color='b')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title("Precision-Recall curve  {}".format(average_precision))